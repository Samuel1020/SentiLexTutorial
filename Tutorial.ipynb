{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from socialsent import lexicons\n",
    "from socialsent import seeds\n",
    "from socialsent.polarity_induction_methods import random_walk\n",
    "from socialsent.evaluate_methods import binary_metrics\n",
    "from socialsent.representations.representation_factory import create_representation\n",
    "\n",
    "from LMLexicon import LMLexicon\n",
    "from IMDB import IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just helper functions\n",
    "def most_sim(embedding, word):\n",
    "    word_scores = embedding.most_similar(word)\n",
    "    return [(word, round(float(score), 3)) for word, score in word_scores]\n",
    "\n",
    "def eval_words(embedding, not_included, lexicon):\n",
    "    return [word for word in embedding.iw if word not in not_included and lexicon.get(word, False)]\n",
    "\n",
    "def evaluate_lexicon(generated_lex, embedding, seeds, lexicon):\n",
    "    word_eval = eval_words(embedding, seeds, lexicon)\n",
    "    auc, avg_per  = binary_metrics(generated_lex, lexicon, word_eval)\n",
    "    print(\"ROC AUC: {:0.2f}\".format(auc))\n",
    "    print(\"Average precision score: {:0.2f}\".format(avg_per))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a lexicon\n",
    "\n",
    "We are going to create a domain specific lexicon using the method stated in this [paper](http://aclweb.org/anthology/D16-1057). The code for the paper was released [here](https://github.com/williamleif/socialsent) and I have modified it so that it can be used in Python 3 which can be found [here](https://github.com/apmoore1/socialsent). The method is based on word embeddings and even though in their paper they state that using Word2Vec models tend to perform poorly we are going to use them due to the ease in creating them.\n",
    "\n",
    "Therefore the first job is to create the word embeddings we are going to use through out this notebook which are:\n",
    "1. Financial word embeddings which we have taken from this [paper](https://arxiv.org/pdf/1705.00571.pdf) and have been pre-trained on financial articles e.g. The Times.\n",
    "2. Movie review word embeddings which have been pre-trained but the method to train and create them can be found in this [class](IMDB.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_embeddings = os.path.abspath(os.path.join('word2vec_models', 'finance', 'all_fin_model_lower'))\n",
    "fin_embeddings = Word2Vec.load(fin_embeddings)\n",
    "\n",
    "movie_embeddings = IMDB().vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have done that we should have a look at the differences between the two word embedding models so that we can tell the differences. Have a go at changing the text values in the *most_similar* function argument. Hopefully you will see a difference between the finance embedding model and the movie model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fin good</th>\n",
       "      <th>Fin Sains</th>\n",
       "      <th>Movie good</th>\n",
       "      <th>Movie film</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(great, 0.688)</td>\n",
       "      <td>(tesco, 0.673)</td>\n",
       "      <td>(decent, 0.751)</td>\n",
       "      <td>(movie, 0.936)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(solid, 0.643)</td>\n",
       "      <td>(asda, 0.562)</td>\n",
       "      <td>(great, 0.668)</td>\n",
       "      <td>(picture, 0.688)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(decent, 0.64)</td>\n",
       "      <td>(morrison, 0.516)</td>\n",
       "      <td>(fine, 0.646)</td>\n",
       "      <td>(flick, 0.659)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(encouraging, 0.622)</td>\n",
       "      <td>(morrisons, 0.508)</td>\n",
       "      <td>(solid, 0.64)</td>\n",
       "      <td>(sequel, 0.595)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(pleasing, 0.619)</td>\n",
       "      <td>(marston, 0.48)</td>\n",
       "      <td>(passable, 0.624)</td>\n",
       "      <td>(films, 0.561)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(healthy, 0.593)</td>\n",
       "      <td>(lowe, 0.479)</td>\n",
       "      <td>(nice, 0.623)</td>\n",
       "      <td>(entry, 0.553)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(strong, 0.591)</td>\n",
       "      <td>(macy, 0.479)</td>\n",
       "      <td>(terrific, 0.612)</td>\n",
       "      <td>(installment, 0.551)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(excellent, 0.583)</td>\n",
       "      <td>(waitrose, 0.478)</td>\n",
       "      <td>(bad, 0.611)</td>\n",
       "      <td>(pic, 0.538)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(terrible, 0.579)</td>\n",
       "      <td>(wendy, 0.464)</td>\n",
       "      <td>(well-done, 0.599)</td>\n",
       "      <td>(it, 0.53)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(terrific, 0.564)</td>\n",
       "      <td>(grocer, 0.447)</td>\n",
       "      <td>(fantastic, 0.585)</td>\n",
       "      <td>(story, 0.529)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fin good           Fin Sains          Movie good  \\\n",
       "0        (great, 0.688)      (tesco, 0.673)     (decent, 0.751)   \n",
       "1        (solid, 0.643)       (asda, 0.562)      (great, 0.668)   \n",
       "2        (decent, 0.64)   (morrison, 0.516)       (fine, 0.646)   \n",
       "3  (encouraging, 0.622)  (morrisons, 0.508)       (solid, 0.64)   \n",
       "4     (pleasing, 0.619)     (marston, 0.48)   (passable, 0.624)   \n",
       "5      (healthy, 0.593)       (lowe, 0.479)       (nice, 0.623)   \n",
       "6       (strong, 0.591)       (macy, 0.479)   (terrific, 0.612)   \n",
       "7    (excellent, 0.583)   (waitrose, 0.478)        (bad, 0.611)   \n",
       "8     (terrible, 0.579)      (wendy, 0.464)  (well-done, 0.599)   \n",
       "9     (terrific, 0.564)     (grocer, 0.447)  (fantastic, 0.585)   \n",
       "\n",
       "             Movie film  \n",
       "0        (movie, 0.936)  \n",
       "1      (picture, 0.688)  \n",
       "2        (flick, 0.659)  \n",
       "3       (sequel, 0.595)  \n",
       "4        (films, 0.561)  \n",
       "5        (entry, 0.553)  \n",
       "6  (installment, 0.551)  \n",
       "7          (pic, 0.538)  \n",
       "8            (it, 0.53)  \n",
       "9        (story, 0.529)  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_good = pd.Series(most_sim(fin_embeddings, 'good'))\n",
    "fin_sains = pd.Series(most_sim(fin_embeddings, 'sainsbury'))\n",
    "movie_good = pd.Series(most_sim(movie_embeddings, 'good'))\n",
    "movie_film = pd.Series(most_sim(movie_embeddings, 'film'))\n",
    "together = pd.concat([fin_good, fin_sains, movie_good, movie_film],axis=1)\n",
    "together.columns = ['Fin good', 'Fin Sains', 'Movie good', 'Movie film']\n",
    "together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create domain specific lexicons from these word embeddings we have to give them some **seed sentiment** words in the domain we want them to be specialised in. In this case it is going to be finance. Therefore we are going to get 10 positive and 10 negative seed sentiment words and create a sentiment specific lexicon and evaluate using the following metric:\n",
    "1. [ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n",
    "2. [Precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    "\n",
    "Good description of the [difference](https://www.quora.com/What-is-the-difference-between-a-ROC-curve-and-a-precision-recall-curve-When-should-I-use-each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluting the finance embeddings as finance sentiment lexicon\n",
      "ROC AUC: 0.82\n",
      "Average precision score: 0.47\n",
      "\n",
      "Evaluting the movie embeddings as finance sentiment lexicon\n",
      "ROC AUC: 0.75\n",
      "Average precision score: 0.51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finance_lex = LMLexicon().lexicon\n",
    "\n",
    "# Getting all of the financial sentiment seeds\n",
    "fin_pos_seeds, fin_neg_seeds = seeds.finance_seeds()\n",
    "all_fin_seeds = set(finance_lex.keys()).union(set(fin_pos_seeds)).union(set(fin_neg_seeds))\n",
    "\n",
    "# Manipulating the movie and financial word embeddings so that they only contain the financial \n",
    "# sentiment seeds to speed up processing\n",
    "fin_fin_embeddings = create_representation('GENSIM', fin_embeddings, words=all_fin_seeds)\n",
    "fin_movie_embeddings = create_representation('GENSIM', movie_embeddings, words=all_fin_seeds)\n",
    "\n",
    "# Creating financial sepcific sentiment lexicons from the finacial and movie word embeddings\n",
    "fin_fin_polarities = random_walk(fin_fin_embeddings, fin_pos_seeds, fin_neg_seeds, beta=0.99, \n",
    "                                 nn=10,sym=True, arccos=True)\n",
    "fin_movie_polarities = random_walk(fin_movie_embeddings, fin_pos_seeds, fin_neg_seeds, beta=0.99, \n",
    "                                   nn=10,sym=True, arccos=True)\n",
    "\n",
    "# \n",
    "# Evaluating against the finance lexicon\n",
    "#\n",
    "print('Evaluting the finance embeddings as finance sentiment lexicon')\n",
    "evaluate_lexicon(fin_fin_polarities, fin_fin_embeddings, fin_pos_seeds + fin_neg_seeds, finance_lex)\n",
    "print('Evaluting the movie embeddings as finance sentiment lexicon')\n",
    "evaluate_lexicon(fin_movie_polarities, fin_movie_embeddings, fin_pos_seeds + fin_neg_seeds, finance_lex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to use the movie and finance embeddings to create a general sentiment lexicon and compare it to the general inquirer which is a general sentiment lexicon. We will see which is better for this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluting the finance embeddings as general sentiment lexicon\n",
      "ROC AUC: 0.64\n",
      "Average precision score: 0.64\n",
      "\n",
      "Evaluting the movie embeddings as general sentiment lexicon\n",
      "ROC AUC: 0.72\n",
      "Average precision score: 0.72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inquirer_lex = lexicons.load_lexicon(\"inquirer\", remove_neutral=True)\n",
    "\n",
    "# Getting all of the general sentiment seeds\n",
    "gen_pos_seeds, gen_neg_seeds = seeds.hist_seeds()\n",
    "all_gen_seeds = set(inquirer_lex.keys()).union(set(gen_pos_seeds)).union(set(gen_neg_seeds))\n",
    "\n",
    "# Manipulating the movie and financial word embeddings so that they only contain the general \n",
    "# sentiment seeds to speed up processing\n",
    "gen_fin_embeddings = create_representation('GENSIM', fin_embeddings, words=all_gen_seeds)\n",
    "gen_movie_embeddings = create_representation('GENSIM', movie_embeddings, words=all_gen_seeds)\n",
    "\n",
    "# Creating general sentiment lexicons from the finacial and movie word embeddings\n",
    "gen_fin_polarities = random_walk(gen_fin_embeddings, gen_pos_seeds, gen_neg_seeds, beta=0.90, \n",
    "                                 nn=20,sym=True, arccos=True)\n",
    "gen_movie_polarities = random_walk(gen_movie_embeddings, gen_pos_seeds, gen_neg_seeds, beta=0.90, \n",
    "                                   nn=20,sym=True, arccos=True)\n",
    "\n",
    "# \n",
    "# Evaluating against the general lexicon\n",
    "#\n",
    "print('Evaluting the finance embeddings as general sentiment lexicon')\n",
    "evaluate_lexicon(gen_fin_polarities, gen_fin_embeddings, gen_pos_seeds + gen_neg_seeds, inquirer_lex)\n",
    "print('Evaluting the movie embeddings as general sentiment lexicon')\n",
    "evaluate_lexicon(gen_movie_polarities, gen_movie_embeddings, gen_pos_seeds + gen_neg_seeds, inquirer_lex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p^{(t+1)} = \\beta \\textbf{T} p^{(t)} + (1 - \\beta)s$$\n",
    "\n",
    "This equation is what controls the sentiment propagation through the word embeddings to define the polarity of words. This equation as you can see depends on the value of $ \\beta $. The larger $ \\beta $ the more of an effect the original sentiment seed words have on the finishing sentiment lexicon. The smaller $ \\beta $ the larger the affect the similarity between words are defined by the word embeddings.\n",
    "\n",
    "As you can see the $ \\beta $ value can be manipulated in the two cells above within the random_walk function. See what happens to the evaluation metrics when you: \n",
    "1. change the value of $ \\beta $\n",
    "2. Change the value of $ nn $ which defines the number of nearest words for each word the algorthim should spread the sentiment values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_dataframe(list_polarities, reverse=True):\n",
    "    '''Given a list of lists that contain tuples of (word, sentiment value) it sorts\n",
    "    the lists by sentiment value and returns words in pandas dataframe sorted by polarity.\n",
    "    '''\n",
    "    polarity_dfs = []\n",
    "    for word_polaritys in list_polarities:\n",
    "        word_order = sorted(word_polaritys.items(), key=lambda item: item[1], reverse=reverse)\n",
    "        polarity_words = None\n",
    "        polarity_dfs.append(pd.Series([word for word, pol in word_order]))\n",
    "    polarity_df = pd.concat(polarity_dfs, ignore_index=True, axis=1)\n",
    "    return polarity_df\n",
    "\n",
    "columns = ['Fin Fin','Fin Movie','Gen Movie','Gen Fin']\n",
    "compare_pos_polaritys = polarity_dataframe([fin_fin_polarities, fin_movie_polarities, \n",
    "                                            gen_movie_polarities, gen_fin_polarities])\n",
    "compare_neg_polaritys = polarity_dataframe([fin_fin_polarities, fin_movie_polarities, \n",
    "                                            gen_movie_polarities, gen_fin_polarities], False)\n",
    "compare_pos_polaritys.columns = columns\n",
    "compare_neg_polaritys.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare_pos_polaritys and compare_neg_polaritys are the sentiment lexicons ranked by the most positive and most negative sentiment words i.e. the first word in compare_pos_polaritys is the most positive word for the sentiment lexicons.\n",
    "\n",
    "1. Compare the sentiment lexicons that have been created based on different word embeddings and seed values.\n",
    "2. Change the value in the head function and see how much they change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fin Fin</th>\n",
       "      <th>Fin Movie</th>\n",
       "      <th>Gen Movie</th>\n",
       "      <th>Gen Fin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>improving</td>\n",
       "      <td>excellent</td>\n",
       "      <td>excellent</td>\n",
       "      <td>fortunate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>improved</td>\n",
       "      <td>successful</td>\n",
       "      <td>perfect</td>\n",
       "      <td>loved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent</td>\n",
       "      <td>improved</td>\n",
       "      <td>lovely</td>\n",
       "      <td>lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>success</td>\n",
       "      <td>gains</td>\n",
       "      <td>delightful</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>successful</td>\n",
       "      <td>improving</td>\n",
       "      <td>wonderful</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>beneficial</td>\n",
       "      <td>profit</td>\n",
       "      <td>marvelous</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>beneficial</td>\n",
       "      <td>fantastic</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>encouraging</td>\n",
       "      <td>success</td>\n",
       "      <td>brilliant</td>\n",
       "      <td>pleasant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>strong</td>\n",
       "      <td>positive</td>\n",
       "      <td>fabulous</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>improves</td>\n",
       "      <td>brilliant</td>\n",
       "      <td>sensational</td>\n",
       "      <td>enjoyable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>improvements</td>\n",
       "      <td>fantastic</td>\n",
       "      <td>flawless</td>\n",
       "      <td>motivated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stabilizing</td>\n",
       "      <td>great</td>\n",
       "      <td>terrific</td>\n",
       "      <td>affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>strengthening</td>\n",
       "      <td>incredible</td>\n",
       "      <td>magnificent</td>\n",
       "      <td>helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stronger</td>\n",
       "      <td>tremendous</td>\n",
       "      <td>splendid</td>\n",
       "      <td>willing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>impressive</td>\n",
       "      <td>exceptional</td>\n",
       "      <td>amazing</td>\n",
       "      <td>able</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gains</td>\n",
       "      <td>impressive</td>\n",
       "      <td>superlative</td>\n",
       "      <td>apt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>exciting</td>\n",
       "      <td>perfect</td>\n",
       "      <td>incredible</td>\n",
       "      <td>daring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stabilization</td>\n",
       "      <td>strong</td>\n",
       "      <td>outstanding</td>\n",
       "      <td>frugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>unsatisfactory</td>\n",
       "      <td>delightful</td>\n",
       "      <td>masterful</td>\n",
       "      <td>interested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>deteriorating</td>\n",
       "      <td>accomplished</td>\n",
       "      <td>perfection</td>\n",
       "      <td>responsive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tightening</td>\n",
       "      <td>spectacular</td>\n",
       "      <td>sublime</td>\n",
       "      <td>loyal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>better</td>\n",
       "      <td>exemplary</td>\n",
       "      <td>remarkable</td>\n",
       "      <td>reactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>strength</td>\n",
       "      <td>best</td>\n",
       "      <td>great</td>\n",
       "      <td>eager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>easing</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>stupendous</td>\n",
       "      <td>receptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>strengthened</td>\n",
       "      <td>popular</td>\n",
       "      <td>fortunate</td>\n",
       "      <td>careful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>worsening</td>\n",
       "      <td>critically</td>\n",
       "      <td>fine</td>\n",
       "      <td>plentiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>weakened</td>\n",
       "      <td>influential</td>\n",
       "      <td>spectacular</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>improve</td>\n",
       "      <td>acclaimed</td>\n",
       "      <td>tremendous</td>\n",
       "      <td>unwilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>improvement</td>\n",
       "      <td>controversial</td>\n",
       "      <td>unforgettable</td>\n",
       "      <td>superior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>weaker</td>\n",
       "      <td>staggering</td>\n",
       "      <td>gorgeous</td>\n",
       "      <td>grateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>satisfactory</td>\n",
       "      <td>profitable</td>\n",
       "      <td>glorious</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>deteriorated</td>\n",
       "      <td>distinctive</td>\n",
       "      <td>notable</td>\n",
       "      <td>celebrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>great</td>\n",
       "      <td>versatile</td>\n",
       "      <td>extraordinary</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>stabilized</td>\n",
       "      <td>good</td>\n",
       "      <td>impressive</td>\n",
       "      <td>keen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sluggish</td>\n",
       "      <td>greatest</td>\n",
       "      <td>grace</td>\n",
       "      <td>susceptible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tremendous</td>\n",
       "      <td>favorite</td>\n",
       "      <td>priceless</td>\n",
       "      <td>better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>weak</td>\n",
       "      <td>assured</td>\n",
       "      <td>commendable</td>\n",
       "      <td>educated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>exemplary</td>\n",
       "      <td>proficient</td>\n",
       "      <td>good</td>\n",
       "      <td>robust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>poor</td>\n",
       "      <td>prestigious</td>\n",
       "      <td>best</td>\n",
       "      <td>dependable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>weakening</td>\n",
       "      <td>innovative</td>\n",
       "      <td>genius</td>\n",
       "      <td>understood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fin Fin      Fin Movie      Gen Movie      Gen Fin\n",
       "0        improving      excellent      excellent    fortunate\n",
       "1         improved     successful        perfect        loved\n",
       "2        excellent       improved         lovely       lovely\n",
       "3          success          gains     delightful        happy\n",
       "4       successful      improving      wonderful         love\n",
       "5       beneficial         profit      marvelous         good\n",
       "6         positive     beneficial      fantastic    excellent\n",
       "7      encouraging        success      brilliant     pleasant\n",
       "8           strong       positive       fabulous      perfect\n",
       "9         improves      brilliant    sensational    enjoyable\n",
       "10    improvements      fantastic       flawless    motivated\n",
       "11     stabilizing          great       terrific     affluent\n",
       "12   strengthening     incredible    magnificent      helpful\n",
       "13        stronger     tremendous       splendid      willing\n",
       "14      impressive    exceptional        amazing         able\n",
       "15           gains     impressive    superlative          apt\n",
       "16        exciting        perfect     incredible       daring\n",
       "17   stabilization         strong    outstanding       frugal\n",
       "18  unsatisfactory     delightful      masterful   interested\n",
       "19   deteriorating   accomplished     perfection   responsive\n",
       "20      tightening    spectacular        sublime        loyal\n",
       "21          better      exemplary     remarkable     reactive\n",
       "22        strength           best          great        eager\n",
       "23          easing      beautiful     stupendous    receptive\n",
       "24    strengthened        popular      fortunate      careful\n",
       "25       worsening     critically           fine    plentiful\n",
       "26        weakened    influential    spectacular         best\n",
       "27         improve      acclaimed     tremendous    unwilling\n",
       "28     improvement  controversial  unforgettable     superior\n",
       "29          weaker     staggering       gorgeous     grateful\n",
       "30    satisfactory     profitable       glorious      healthy\n",
       "31    deteriorated    distinctive        notable    celebrate\n",
       "32           great      versatile  extraordinary        great\n",
       "33      stabilized           good     impressive         keen\n",
       "34        sluggish       greatest          grace  susceptible\n",
       "35      tremendous       favorite      priceless       better\n",
       "36            weak        assured    commendable     educated\n",
       "37       exemplary     proficient           good       robust\n",
       "38            poor    prestigious           best   dependable\n",
       "39       weakening     innovative         genius   understood"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_pos_polaritys.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fin Fin</th>\n",
       "      <th>Fin Movie</th>\n",
       "      <th>Gen Movie</th>\n",
       "      <th>Gen Fin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>litigation</td>\n",
       "      <td>down</td>\n",
       "      <td>evil</td>\n",
       "      <td>unfortunate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>damages</td>\n",
       "      <td>negligent</td>\n",
       "      <td>unhappy</td>\n",
       "      <td>unpleasant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negligent</td>\n",
       "      <td>litigation</td>\n",
       "      <td>disgusting</td>\n",
       "      <td>evil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>failure</td>\n",
       "      <td>damages</td>\n",
       "      <td>unpleasant</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>losses</td>\n",
       "      <td>loss</td>\n",
       "      <td>unfortunate</td>\n",
       "      <td>hated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wrong</td>\n",
       "      <td>losses</td>\n",
       "      <td>hate</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>claims</td>\n",
       "      <td>wrong</td>\n",
       "      <td>absurd</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loss</td>\n",
       "      <td>volatile</td>\n",
       "      <td>ridiculous</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>injunctions</td>\n",
       "      <td>failure</td>\n",
       "      <td>unbelievable</td>\n",
       "      <td>abrupt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>penalties</td>\n",
       "      <td>negative</td>\n",
       "      <td>loveless</td>\n",
       "      <td>epidemic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>punitive</td>\n",
       "      <td>bad</td>\n",
       "      <td>idiotic</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fines</td>\n",
       "      <td>damage</td>\n",
       "      <td>pathetic</td>\n",
       "      <td>ominous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>penalty</td>\n",
       "      <td>prematurely</td>\n",
       "      <td>vile</td>\n",
       "      <td>impediment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>investigations</td>\n",
       "      <td>misused</td>\n",
       "      <td>depraved</td>\n",
       "      <td>invitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>clawback</td>\n",
       "      <td>disagreeable</td>\n",
       "      <td>perverse</td>\n",
       "      <td>horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>verdict</td>\n",
       "      <td>misdirected</td>\n",
       "      <td>ugly</td>\n",
       "      <td>outright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bad</td>\n",
       "      <td>disagreed</td>\n",
       "      <td>senseless</td>\n",
       "      <td>abundance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>plaintiff</td>\n",
       "      <td>mishandled</td>\n",
       "      <td>inhumane</td>\n",
       "      <td>unpopular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>infringement</td>\n",
       "      <td>recklessly</td>\n",
       "      <td>nasty</td>\n",
       "      <td>embarrassment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>down</td>\n",
       "      <td>disapproving</td>\n",
       "      <td>immoral</td>\n",
       "      <td>blunder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>negligence</td>\n",
       "      <td>delinquent</td>\n",
       "      <td>repulsive</td>\n",
       "      <td>awkward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>plaintiffs</td>\n",
       "      <td>misjudged</td>\n",
       "      <td>hated</td>\n",
       "      <td>rebuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>disputes</td>\n",
       "      <td>terminated</td>\n",
       "      <td>hideous</td>\n",
       "      <td>obstacle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>unpaid</td>\n",
       "      <td>underutilized</td>\n",
       "      <td>despicable</td>\n",
       "      <td>advocacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>malpractice</td>\n",
       "      <td>unfavorably</td>\n",
       "      <td>dumb</td>\n",
       "      <td>exaggeration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>volatile</td>\n",
       "      <td>prosecuting</td>\n",
       "      <td>indifferent</td>\n",
       "      <td>acrimonious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>unauthorized</td>\n",
       "      <td>disqualified</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>accomplishment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>forfeitures</td>\n",
       "      <td>sentencing</td>\n",
       "      <td>alien</td>\n",
       "      <td>unsuccessful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>injury</td>\n",
       "      <td>repossessing</td>\n",
       "      <td>offensive</td>\n",
       "      <td>outsider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>malicious</td>\n",
       "      <td>carelessly</td>\n",
       "      <td>pitiful</td>\n",
       "      <td>avid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>failing</td>\n",
       "      <td>carelessness</td>\n",
       "      <td>cruel</td>\n",
       "      <td>opportune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>overturn</td>\n",
       "      <td>reckless</td>\n",
       "      <td>useless</td>\n",
       "      <td>auspicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>defendant</td>\n",
       "      <td>disproportionate</td>\n",
       "      <td>orphan</td>\n",
       "      <td>retard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>negative</td>\n",
       "      <td>neglectful</td>\n",
       "      <td>violent</td>\n",
       "      <td>erroneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>inability</td>\n",
       "      <td>impaired</td>\n",
       "      <td>pointless</td>\n",
       "      <td>acknowledgement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>unable</td>\n",
       "      <td>unfit</td>\n",
       "      <td>insignificant</td>\n",
       "      <td>alarming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>circumvention</td>\n",
       "      <td>cancelling</td>\n",
       "      <td>meaningless</td>\n",
       "      <td>ultimatum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>infringing</td>\n",
       "      <td>acquiesces</td>\n",
       "      <td>dismiss</td>\n",
       "      <td>overwhelming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>breaches</td>\n",
       "      <td>persistently</td>\n",
       "      <td>illogical</td>\n",
       "      <td>indefinite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>misuse</td>\n",
       "      <td>injuries</td>\n",
       "      <td>ludicrous</td>\n",
       "      <td>undesirable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fin Fin         Fin Movie      Gen Movie          Gen Fin\n",
       "0       litigation              down           evil      unfortunate\n",
       "1          damages         negligent        unhappy       unpleasant\n",
       "2        negligent        litigation     disgusting             evil\n",
       "3          failure           damages     unpleasant          unhappy\n",
       "4           losses              loss    unfortunate            hated\n",
       "5            wrong            losses           hate              bad\n",
       "6           claims             wrong         absurd             poor\n",
       "7             loss          volatile     ridiculous             hate\n",
       "8      injunctions           failure   unbelievable           abrupt\n",
       "9        penalties          negative       loveless         epidemic\n",
       "10        punitive               bad        idiotic          anomaly\n",
       "11           fines            damage       pathetic          ominous\n",
       "12         penalty       prematurely           vile       impediment\n",
       "13  investigations           misused       depraved       invitation\n",
       "14        clawback      disagreeable       perverse         horrible\n",
       "15         verdict       misdirected           ugly         outright\n",
       "16             bad         disagreed      senseless        abundance\n",
       "17       plaintiff        mishandled       inhumane        unpopular\n",
       "18    infringement        recklessly          nasty    embarrassment\n",
       "19            down      disapproving        immoral          blunder\n",
       "20      negligence        delinquent      repulsive          awkward\n",
       "21      plaintiffs         misjudged          hated           rebuff\n",
       "22        disputes        terminated        hideous         obstacle\n",
       "23          unpaid     underutilized     despicable         advocacy\n",
       "24     malpractice       unfavorably           dumb     exaggeration\n",
       "25        volatile       prosecuting    indifferent      acrimonious\n",
       "26    unauthorized      disqualified      incorrect   accomplishment\n",
       "27     forfeitures        sentencing          alien     unsuccessful\n",
       "28          injury      repossessing      offensive         outsider\n",
       "29       malicious        carelessly        pitiful             avid\n",
       "30         failing      carelessness          cruel        opportune\n",
       "31        overturn          reckless        useless       auspicious\n",
       "32       defendant  disproportionate         orphan           retard\n",
       "33        negative        neglectful        violent        erroneous\n",
       "34       inability          impaired      pointless  acknowledgement\n",
       "35          unable             unfit  insignificant         alarming\n",
       "36   circumvention        cancelling    meaningless        ultimatum\n",
       "37      infringing        acquiesces        dismiss     overwhelming\n",
       "38        breaches      persistently      illogical       indefinite\n",
       "39          misuse          injuries      ludicrous      undesirable"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_neg_polaritys.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
